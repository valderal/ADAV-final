---
title: "Final Assignment"
author: "Osman Bahadir, Timo Scholts, Valerie Schilting"
date: "2024-06-11"
output:
  html_document:
    toc: true
    number_sections: true
    toc_float: true
    code_folding: show
    theme: cosmo
---

# Introduction
Pokemon come in a broad variety of designs and abilities, from the well-known Pikachu to box legendaries as Zamazenta and Lugia.
Each Pokemon has different "stats" that decide how powerful its attacks are, or how quickly their turn is in battle.
The stats are shortly explained below:

* HP: how much hit points a Pokemon has in total, and thus how much damage it can take before it faints;
* Attack: how much damage a physical attack does;
* Defense: how much damage a Pokemon actually takes from a physical attack;
* Special Attack: how much damage a special attack does;
* Special Defense: how much damage a Pokemon actually takes from a special attack;
* Speed: when the Pokemon can take its turn in battle - higher speed means it's more likely to go first.

These stats together make up the base total stats, which is simply the sum of all other stats.
Earlier stage Pokemon in the evolution line, such as Charmander or Smoliv, will have lower base stats than their final stage evolutions.
Pokemon that appear in starting areas also tend to have lower base total stats compared to those in later areas of the games.
Legendary and pseudo-legendary Pokemon often have the highest base total stats, with 780 being currently the highest for Mega Mewtwo X and Y, and Mega Rayquaza.
With patterns like these being present, it is interesting to look at how prevalent these patterns actually are, and if they are statistically significant or not.
To do this, we use [The Complete Pokemon Dataset](https://www.kaggle.com/datasets/rounakbanik/pokemon) from Kaggle.
This dataset contains information on all 802 Pokemon from Generation 1 through 7, such as English and Japanese names, typing, base stats, base happiness, etc.

The research question we are trying to answer is:

<center>

_What attributes of a Pokemon contribute to higher base stats?_

</center>

# Data exploration
## Data cleaning
```{r, chunk options, echo = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

```{r, library}
library(tidyverse)
library(caret)
library(ggpubr)
library(knitr)
library(kableExtra)
library(report)
```

```{r, data preprocessing}
# setting seed for easy duplication
set.seed(48645156)

# importing the dataset from the \data folder
pokemon <- read_csv("data/pokemon_sort.csv")
data.frame(head(pokemon, 3)) 

# removing unused columns
pokemon <- select(pokemon, -c("japanese_name", "abilities", "classfication", 
                              "attack":"speed", "percentage_male"))

# check if column are the correct class
sapply(pokemon, class)
pokemon$capture_rate <- as.numeric(pokemon$capture_rate)

# NA introduced to coercion, so searching for it and correcting it
item_count <- 1
for (item in pokemon$capture_rate) {
  if (is.na(item) == TRUE) {
    print(pokemon[item_count, ])
    item_count <- item_count + 1
  } else {
    item_count <- item_count + 1
  }
}

# minior has two forms that it switches to if it falls below 50% HP, so the new
# capture rate value will be the average of the two forms
pokemon[774, "capture_rate"] <- (30+255)/2

# search for NA's and see if they need to be replaced or not
column_list <- colnames(pokemon)
item_count <- 1
for (col in column_list) {
  if (sum(is.na(pokemon[item_count])) == 0) {
    item_count <- item_count + 1
  } else {
      cat(col, ":\n", sum(is.na(pokemon[item_count])), "\n")
      item_count <- item_count + 1
  }
}

# changing type2 NA's to be none, and adding pokemon to single_type dummy
pokemon$single_type <- 0
item_count <- 1
for (item in pokemon$type2) {
  if (is.na(item) == TRUE) {
    pokemon[item_count, "type2"] <- "none"
    pokemon[item_count, "single_type"] <- 1
    item_count <- item_count + 1
  } else {
    item_count <- item_count + 1
  }
}

# changing the NA's for height and weight to be filled with column mean
# Function to fill NaN values with column mean
fill_na_with_mean <- function(df, column) {
  df %>% 
    mutate(!!sym(column) := ifelse(is.na(!!sym(column)), mean(!!sym(column), 
                                                              na.rm = TRUE), 
                                   !!sym(column)))
}  

# Columns to fill NaN values
columns_to_fill <- c("height_m", "weight_kg")

# Fill NaN values for each specified column
for (col in columns_to_fill) {
  pokemon <- fill_na_with_mean(pokemon, col)
}

# add dummy variables for each type
all_values <- c("poison", "flying", "dark", "electric", "ice", "ground", "fairy", 
                "grass", "fighting", "psychic", "steel", "fire", "rock", "water", 
                "dragon", "ghost", "bug", "normal")

# Create new columns for each value and fill with 1 or 0 based on type1 and type2
for (val in all_values) {
  pokemon <- pokemon %>%
    mutate(!!val := as.numeric(type1 == val | type2 == val))
}
```

There are several variables with missing values, namely: `type2`, `height_m` and `weight_kg`.
The missingness for `type2` is due to not all Pokemon having a secondary typing.
To solve this, we change the value for those to be "none".
However, the missingness for `height_m` and `weight_kg` is likely due to incorrect scraping from [Serebii](https://www.serebii.net/), and thus will be filled in using the column means.

There was also one NA introduced in `capture_rate` due to coercion into numeric values.
This ended up being the Pokemon Minior, which has two forms: its Meteor form, which has a capture rate of 30, and its Core form, which has a capture rate of 255.
To solve this, we changed the `capture_rate` value for Minior to be the average between its two forms, since it switches once it HP falls below 50%.

## Data visualizations
### Violin plot
The violin plot below shows per type the distribution of the base total statistic. 
The types are sorted  from high mean base total  to low mean base total. 
As shown in the graph the dragon type has the highest base stat on average. 
When taking a closer look of the distribution of this type you can see that on the high end, between 600 and 800 there is a higher amount of dragon type Pokemon. 
The dragon type not only has the highest base total statistic on average, but it also seems to contain the Pokemon with the highest base total statistic. 
The steel type is the second highest type for the mean base total statistic. 
The range of this type is much smaller than the dragon type. 
There are no Pokemon on the high end of more than 700 base total stat and also no Pokemon on the low end of less then 300. 
The bug type has on average the lowest base stat of all types. 
The distribution shows that there are no Pokemon on the high end (>600) or the very high end (>700) and also there is a large amount of bug type pokemon of the low end (<300). 
There are several violin plots that show two bulges which is especially apparent for the poison type. 
An explanation for this is that when Pokemon evolve into their evolution their base stat jumps to above the average. 
So because of the evolution trait of Pokemon it can be stated that the types are not normally distributed. 
There will probably be a normal distribution among the Pokemon when the first second and final evolution will be split. 
But the dataset does not contain information about whether the Pokemon is a first, second or third evolution. 
It needs to be taken into account that the types of the Pokemon are split into a single type. 
This means that there will be no insight in the distribution in the combinations of types.

```{r, violin colors}
# the pokemon types have a certain color that has to be attached to it. 
# this will be done by writing a feature that will attach the applicable hex 
# color to the type name
colors <- c("normal" = "#A8A77A",
            "fire"= "#EE8130",
            "water"= "#6390F0",
            "electric"= "#F7D02C",
            "grass"= "#7AC74C",
            "ice"="#96D9D6",
            "fighting"= "#C22E28",
            "poison"= "#A33EA1",
            "ground"= "#E2BF65",
            "flying"= "#A98FF3",
            "psychic"= "#F95587",
            "bug"= "#A6B91A",
            "rock"= "#B6A136",
            "ghost"= "#735797",
            "dragon"= "#6F35FC",
            "dark"= "#705746",
            "steel"= "#B7B7CE",
            "fairy"= "#D685AD")
```

```{r, violin  plot}
# In order to compare the base total for each type it needs to be taken into 
# account that pokemon can have two types. for this reason it was decided to 
# duplicate the pokemon that have two types that it can be assigned to both 
# types in the plot that will be made. This is done by filtering the pokemon 
# that do not have NA. These filtered pokemon will then have type2 as the new 
#type 1 and will then be binded with the original dataframe. 
pokemon_with_type2 <- pokemon %>%
  filter(!is.na(type2))

pokemon_with_dups <- pokemon_with_type2 %>%
  mutate(type1 = type2) %>%
  bind_rows(pokemon_with_type2)

pokemon_with_dups <- bind_rows(pokemon, pokemon_with_dups)


# this code is used to order the types according to the mean base total per type. 
# This will order the types for the ggplot that will be made that will compare 
# the base total per type. 
pokemon_with_dups$type1 <- factor(pokemon_with_dups$type1, 
                                  levels = names(sort(tapply(pokemon_with_dups$base_total, 
                                                             pokemon_with_dups$type1, mean), 
                                                      decreasing = TRUE)))


# this code is used to make a violin plot. this will show the distribution per 
# type of pokemon based on thier base total. 
violin_plot2 <- ggplot(pokemon_with_dups, aes(x = type1, 
                                              y = base_total,
                                              fill = type1)) +
  geom_violin() +
  labs(title = "Violin plot of base total stats per type ordered by the mean base
      total of the pokemon for the type",
      x = "Types",  
      y = "Base Total",
      fill = colors) +
  scale_fill_manual(values = colors) + 
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1), 
        legend.position = "none")

violin_plot2
```

### Distribution plot
The bar plots below show the distribution of each Pokemon type as both main type and secondary type.
There is a noticeable lack of Pokemon with Flying as their first type, which seems to be only a thing of the latest two generations.
However, Flying is over represented as a secondary type, with almost 100 Pokemon having Flying as their secondary type.
Water, Normal and Bug are the most common first types for Pokemon, with Bug having a substantial increase in Generation 5.
While Water still has a substantial amount of Pokemon as a secondary type, the same cannot be said for Bug and Normal, which, together with Electric, have the least Pokemon with it as a secondary type.

```{r, type distrubution plot}
# making levels to properly showcase the generations and types in the plots
gen_levels <- c("7", "6", "5", "4", "3", "2", "1")
type2_levels <- c("bug", "dark", "dragon", "electric", "fairy", "fighting", 
                  "fire", "flying", "ghost", "grass", "ground", "ice", "normal",
                  "poison", "psychic", "rock", "steel", "water")

# generating plot with only main type
plot_type1 <- ggplot(pokemon, 
                     aes(x = type1, 
                         fill = factor(generation, levels = gen_levels))
              ) +
  geom_bar(stat = "count") + 
  scale_fill_viridis_d() +
  labs(title = "Pokemon type per generation",
       subtitle = "Distribution for main type",
       x = "Type",
       y = "Count",
       fill = "Generation") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

# generating plot with only secondary type 
plot_type2 <- ggplot(data = subset(pokemon, type2 != "none"),
                     aes(x = factor(type2, levels = type2_levels),
                         fill = factor(generation, levels = gen_levels))
              ) +
  geom_bar(stat = "count") + 
  scale_fill_viridis_d() +
  labs(title = "",      # without this the plots don't align nicely in the grid
       subtitle = "Distribution for secondary type",
       x = "Type",
       y = "Count") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
        legend.position = "none")

# combining both plots with a common legend
ggarrange(plot_type1, plot_type2, common.legend = TRUE, legend = "right")
```


### Correlation matrix
The correlation matrix shows the correlation of each variable with the base total statistic.
In the previous code the type variable was dummy coded so that this would be numerical and be compared with the predictor variable. 
Also some variables where removed as they where each a statistic that the base total statistic is based upon.
The base total statistic is the sum of all these stats. 

In the correlation matrix the top five highest and lowest variables are highlighted.
Capture rate has the highest correlation with the total stats, likely because Pokemon with a higher capture rate tend to be early game Pokemon and/or first stages of the evolution line.
Other variables with notable high correlation are height, legendary status, base egg steps and base happiness.

```{r, correlation matrix}
# delete numeric columns
numeric_pokemon <- pokemon[sapply(pokemon, is.numeric)]

# Calculate the correlation matrix
correlation_matrix <- cor(numeric_pokemon)

# Extract the 'base total' column
base_total_corr <- correlation_matrix[, "base_total"]

# Remove 'base total' self-correlation if present
base_total_corr <- base_total_corr[names(base_total_corr) != "base_total"]

# Sort the correlations
sorted_corr <- sort(base_total_corr, decreasing = TRUE)

# Convert to data frame for ggplot
corr <- data.frame(Parameter = names(sorted_corr), Correlation = sorted_corr)

# Add a column for color classification
corr$Highlight <- "Normal"
corr$Highlight[1:5] <- "Top 5"      # Top 5 correlations
corr$Highlight[(nrow(corr)-4):nrow(corr)] <- "Bottom 5"  # Bottom 5 correlations

# Create a custom color palette
custom_colors <- c("Top 5" = "dodgerblue", "Bottom 5" = "firebrick", 
                   "Normal" = "grey70")

# Create bar plot
ggplot(corr, aes(x = reorder(Parameter, Correlation), y = Correlation, 
                 fill = Highlight)) +
  geom_bar(stat = "identity") +
  scale_fill_manual(values = custom_colors) +
  coord_flip() +
  labs(title = "Correlation with 'Base Total'", x = "Parameter", 
       y = "Correlation") +
  theme_minimal() +
  theme(legend.title = element_blank())

```

# Methods
In order to find out which predictors to choose, we will use best subset selection to determine which variable or variables are best suited as predictor variables for the base stats of a Pokemon, using the train-validation-test splits to fit the model.

## Best subset selection
```{r, data splitting}
# df dataframe with all the useless columns out to create good datasets
df <- select(pokemon, -c("name", "pokedex_number", "type1", "type2", 
                                      "against_bug":"against_water"))

# define the training partition 
train_index <- createDataPartition(df$base_total, p = .5, 
                                  list = FALSE, 
                                  times = 1)

# split the data using the training partition to obtain training data
pokemon_train <- df[train_index,]

# remainder of the split is the validation and test data (still) combined 
pokemon_val_and_test <- df[-train_index,]

# split the remaining 50% of the data in a validation and test set
val_index <- createDataPartition(pokemon_val_and_test$base_total, p = .6, 
                                  list = FALSE, 
                                  times = 1)

pokemon_valid <- pokemon_val_and_test[val_index,]
pokemon_test  <- pokemon_val_and_test[-val_index,]

```

```{r, subset selection}
# MSE function from lab 3
mse <- function(y_true, y_pred) {
  mean((y_true - y_pred)^2)
}

# MSE on a validation dataset for predictions from a linear model function from
# lab 4
lm_mse <- function(formula, train_data, valid_data) {
  y_name <- as.character(formula)[2]
  y_true <- valid_data[[y_name]]
  
  lm_fit <- lm(formula, train_data)
  y_pred <- predict(lm_fit, newdata = valid_data)
  
  mean((y_true - y_pred)^2)
}

# sourcing the generate formulas function from lab 4
source("generate_formulas.R")

# object with all potential predictor variables
x_vars <- colnames(select(df, -base_total))

# function to find the best model for x amount of predictors, using code from
# lab 4
best_n_preds <- function(n) {
  formulas <- generate_formulas(p = n, x_vars = x_vars, y_var = "base_total")
  amount <- length(formulas)
  mses <- rep(0, amount)
  for (i in 1:amount) {
    mses[i] <- lm_mse(as.formula(formulas[i]), pokemon_train, pokemon_valid)
  }
  best_preds <- formulas[which.min(mses)]
  min_mse <- lm_mse(as.formula(best_preds), pokemon_train, pokemon_valid)
  cat(best_preds, "| MSE", min_mse)
}

# find the best models for 1 to 5 predictors
# time to compute on high-end pc: ~3 minutes (as point of reference for how long 
# this will take, especially with laptops this can and will take longer)
for (bip in 1:5) {
  cat(bip, "predictor(s):\n")
  best_n_preds(bip)
  cat("\n")
}

# trying 5 predictor model
mse_5_pred <-lm_mse(base_total ~ generation + is_legendary + height_m + 
                      capture_rate + single_type, pokemon_train, pokemon_valid)
summary(lm(as.formula(base_total ~ generation + is_legendary + height_m + 
                      capture_rate + single_type), data = pokemon_train))

# trying 3 predictor model
summary(lm(base_total ~ is_legendary + height_m + capture_rate, 
           data = pokemon_train))

# saving values of final 3 predictor model
formula_3_pred <- base_total ~ is_legendary + height_m + capture_rate
mse_3_pred <- lm_mse(as.formula(formula_3_pred), pokemon_train, pokemon_valid)
```

According to the best subset selection, the best predictors are `generation`, `is_legendary`, `height_m`, `capture_rate` and `single_type`.
This would give us an MSE of `r mse_5_pred`.
We could have gone further with the best subset selection, however due to computing time and the risk of overfitting it was decided against.
The rate at which the MSE decreased already started to slow down substantially from 3 predictors onward as well, which is a trend very likely to be observed further if we calculated for more predictors.
However, when looking at the significance levels of the 5 predictor regression model, `generation` and `single_type` are not significant at all and should therefore be excluded from the model.
When excluding those variables, we end up with a model that does hold significance for all its variables.

This means that the final model we end up with is `base_total ~ is_legendary + height_m + capture_rate`, which has an MSE of `r mse_3_pred`.

## Training the model
```{r, lab 3 replication}
# training model on train and validation separately
model_train <- lm(as.formula(formula_3_pred), data = pokemon_train)
(model_train_mse <- mse(y_true = pokemon_train$base_total, 
                       y_pred = predict(model_train)))

model_valid_mse <- mse(y_true = pokemon_valid$base_total, 
                         y_pred = predict(object = model_train, 
                                          newdata = pokemon_valid))
cat("Estimated out-of-sample MSE:", model_valid_mse)

# retraining model
model_2 <- lm(as.formula(formula_3_pred), 
              data = bind_rows(pokemon_train, pokemon_valid))
summary(model_2)

model_2_mse_test <- mse(y_true = pokemon_test$base_total, 
                        y_pred = predict(model_2, newdata = pokemon_test))
model_2_mse_test
```

The MSE of the model increased when testing it on the test data.
It went from `r round(model_valid_mse, 0)` to `r round(model_2_mse_test, 0)`, which is an increase of `r round(model_2_mse_test - model_valid_mse, 0)`.
While it is a seemingly large increase, `r round(((model_2_mse_test - model_valid_mse) / model_valid_mse) * 100, 2)`% increase is still low enough to be usable without further tweaking.


# Results

```{r, reg table prep}
# saving the model to a variable for easier calling
model_test <- lm(base_total ~ is_legendary + height_m + capture_rate, 
                 data = pokemon_test)

# make the report package do the hard work of making a summary that can be 
# coerced into a dataframe to make kable usable, and removing unwanted rows and
# columns
model_report <- report(model_test)
df_report <- as.data.frame(model_report)
df_report <- df_report[-c(6,7,8,11), -c(3,9:11)]
colnames(df_report) <- c("Parameter", "Estimate", "CI low", "CI high", 
                         "t-value", "df", "p-value", "Model fit")
```

The results of the multiple linear regression analysis using the test dataset can be found in the table below.
The variables chosen through subset selection explain the variance in the total stats of a Pokemon quite well, with an adjusted $R^2$ of `r round(df_report[7, 8], 2)`, meaning that `r round(df_report[7, 8], 2)`% of the variance in `base_total` can be explained by `capture_rate`, `is_legendary` and `height_m`.

```{r, reg table}
# making sure kable NA are set to nothing so the table isn't filled with NA's
opts <- options(knitr.kable.NA = "")

# regression results table
kable(df_report, 
      digits = 3,
      row.names = FALSE,
      caption = "Linear regression analysis of the effects of legendary status, 
      height and capture rate on the total stats of Pokemon") %>% 
  kable_classic()



```

We found an increase of `r round(df_report[2, 2], 0)` points on the total stats if a Pokemon is legendary while holding the height and capture rate at 0 ($\beta$ = `r round(df_report[2, 2], 3)`, *t* (`r df_report[2, 6]`) = `r round(df_report[2, 5], 3)`, *p* < .001).
For every additional meter a Pokemon is tall, their total stats increase with `r round(df_report[3, 2])` when holding the other variables constant ($\beta$ = `r round(df_report[3, 2], 3)`, *t* (`r df_report[3, 6]`) = `r round(df_report[3, 5], 3)`, *p* < .001).
Capture rate works differently from the other variables, since a higher capture rate means the Pokemon is easier to catch.
Therefore, for every unit increase in capture rate, the total stats decrease with `r round(df_report[4, 2], 2)`points when holding the other variables constant ($\beta$ = `r round(df_report[4, 2], 3)`, *t* (`r df_report[4, 6]`)= `r round(df_report[4, 5], 3)`, *p* < .001).

```{r, regression plot}
# create new dataset for plot specifically
plot_data <- expand.grid(
  capture_rate = pokemon_test$capture_rate,
  height_m = c(min(pokemon_test$height_m),
             mean(pokemon_test$height_m),
             max(pokemon_test$height_m)),
  is_legendary = pokemon_test$is_legendary
)

# predict y with the new dataset and transform continuous variable to make it
# more readable
plot_data$pred_y <- predict.lm(model_test, newdata = plot_data)
plot_data$height_m <- round(plot_data$height_m, 2)

# ggplot of fitted lines
ggplot(pokemon_test, aes(x = capture_rate, y = base_total)) +
  geom_point(size = 1) +
  geom_line(data = plot_data, 
            aes(x = capture_rate, 
                y = pred_y,
                color = as.factor(height_m),
                linetype = as.factor(is_legendary)),
            linewidth = 1) +
  annotate(geom = "text", 
           x = 170, 
           y = 850, 
           label = " = 466 + (-0.737*CR) + (134*L) + (19*H)") +
  labs(title = "Base total stats of a Pokemon as a function 
of capture rate, legendary status and height",
       x = "Capture rate (CR)",
       y = "Base total stats",
       color = "Height in meters (H)",
       linetype = "Legendary status (L)") +
  scale_linetype(labels = c("No", "Yes")) +
  scale_color_viridis_d()
```

The graph above shows the fitted linear regression lines for each variable.
The height is divided to show the minimal, mean and maximal height for easier visualization.
Interestingly, the model gives higher predictions of base total stats than the actual observed total stats.
For instance, the highest possible predicted value (legendary Pokemon, `r max(pokemon_test$height_m)`m, capture rate `r min(pokemon_test$capture_rate)`) is `r round(max(predict(model_test)))`, while the observed highest value `r max(pokemon_test$base_total)` is.
This is also seen for the lowest possible base stat, the predicted value (non-legendary, `r min(pokemon_test$height_m)`m, capture rate `r max(pokemon_test$capture_rate)`) is `r round(min(predict(model_test)))`, while the observed lowest value `r min(pokemon_test$base_total)` is.
The highest and lowest total stats in the complete dataset are `r max(pokemon$base_total)` and `r min(pokemon$base_total)` respectively.

# Conclusion

There are a lot of factors that contribute to the base total stats of a Pokemon, other than the sum of the individual stats of course.
To answer our research question regarding which factors contribute to a higher base stat, we used subset selection to determine which combination of predictors would generate the lowest possible MSE without risking overfitting.
We used train-validation-test splits of the dataset to properly fit the model.
The factors that were found, while still being statistically significant enough, were the capture rate, legendary status and height of the Pokemon.
As seen earlier, these also correlated moderately with the total stats, so it isn't surprising that their relation is statistically significant as well.
We found that tall, legendary Pokemon with a low capture rate are more likely to have higher base total stats than other Pokemon compared to those that are smaller, not legendary and with a high capture rate.
These same results can also be found in our Shiny application, which can be found [here](https://9xk63c-timo-scholts.shinyapps.io/pokemon_shiny/).


# Contributions
## Osman
* Data preprocessing
* Correlation matrix
* Splitting data into train/validation/test sets

## Timo
* Violin plot
* Text for violin plot and correlation matrix
* Code for duplicated Pokemon
* The entire Shiny Application

## Valerie
* Introduction
* Data preprocessing
* Type distribution plot
* Best subset selection and model training
* Results
* Conclusion
* Cleaning up Rmd and code
* Edits based on feedback for distribution plot and correlation matrix
